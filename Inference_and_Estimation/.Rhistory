geom_smooth(method = "lm", se = F)
autoplot(glm.temphum)
suit %>%
ggplot(aes(x = richness)) +
geom_histogram(bins = 10)
suit %>%
ggplot(aes(sample = richness)) +
geom_qq() +
geom_qq_line()
suit %>%
ggplot(aes(x = richness)) +
geom_histogram(bins = 10)
# Forest type:
glm.richfor <- glm(richness ~ foresttype, data = suit)
autoplot(glm.richfor)
glm.richfor <- glm(log(richness) ~ foresttype, data = suit)
autoplot(glm.richfor)
summary(glm.richfor)
suit %>%
ggplot(aes(x= forestype, y = richness)) +
geom_violin()
suit %>%
ggplot(aes(x= foresttype, y = richness)) +
geom_violin()
# Let's let GLM take care of it for us
glm.richfor <- glm(richness ~ foresttype, data = suit, family = "poisson")
autoplot(glm.richfor)
summary(glm.richfor)
# Let's let GLM take care of it for us
glm.richfor <- glm(richness ~ foresttype, data = suit, family = "poisson")
summary(glm.richfor)
str(suit)
suit %>%
ggplot(aes(sample = orchidpa)) +
geom_qq() +
geom_qq_line()
cor.test(suit$species, suit$soilom, method = "pearson")
cor.test(suit$species, suit$soilom, method = "spearman")
suit$species %>% unique()
# Species explanatory data is categorical so we would not do a correlation test.# Test for association anyway:
t.test(soilom ~ species, data = suit)
#3.
glm.specom <- glm(orchidpa ~ species + soilom, data = suit)
#4.
autplot(glm.specom)
#4.
autoplot(glm.specom)
#1.
suit %>%
ggplot(aes(sample = orchidpa)) +
geom_qq() +
geom_qq_line()
#3.
glm.specom <- glm(orchidpa ~ species + soilom, data = suit, family = "binomial")
#4.
autoplot(glm.specom)
#5.
summary(glm.specom)
#5.
anova(glm.specom, test = "F")
#4.
autoplot(glm.specom)
#5.
anova(glm.specom, test = "Chisq")
#5.
anova(glm.specom, test = "F")
#6.
summary(glm.specom)
value <- -0.90356
exp(value)/(1+exp(value))
# Interactions:
glm.int.specom <- glm(orchidpa ~ species * soilom, data = suit, family = "binomial")
glm.int.typden <- glm(temperature ~ foresttype * treedensity, data = suit)
autoplot(glm.int.typden)
anova(glm.int.typden)
summary(glm.int.typden)
anova(glm.int.typden, test = "F")
summary(glm.int.typden)
suit %>%
ggplot(aes(x = treedensity, y = temperature, col = foresttype))
suit %>%
ggplot(aes(x = treedensity, y = temperature, col = foresttype)) +
geom_point()
# Create dummy dataframe
expand_grid(foresttype = suit$foresttype %>% unique,
treedensity = seq(from = 0, to = 0.6, 0.02))
# Create dummy dataframe
glm.inttypden.predict <- expand_grid(foresttype = suit$foresttype %>% unique,
treedensity = seq(from = 0, to = 0.6, 0.02))
predict(glm.int.typden, glm.inttypden.predict, se.fit = T)
glm.inttypden.predictobj <- predict(glm.int.typden, glm.inttypden.predict, se.fit = T)
glm.inttypden.predict <- glm.inttypden.predict %>%
mutate(temperature = glm.inttypden.predictobj$fit, se = glm.inttypden.predictobj$se.fit)
# Add these to our plot
ggplot(mapping = aes(x = treedensity, y = temperature, col = foresttype)) + # Note the mapping = aes
geom_point(data = suit) +
geom_line(data = glm.inttypden.predict)
# Add these to our plot!! More manual way
ggplot(mapping = aes(x = treedensity, y = temperature, col = foresttype)) + # Note the mapping = aes
geom_point(data = suit) +
geom_line(data = glm.inttypden.predict) +
geom_ribbon(data = glm.inttypden.predict$se)
# Add these to our plot!! More manual way
ggplot(mapping = aes(x = treedensity, y = temperature, col = foresttype)) + # Note the mapping = aes
geom_point(data = suit) +
geom_line(data = glm.inttypden.predict) +
geom_ribbon(data = glm.inttypden.predict, mapping = aes(ymin = temperature - se, ymax = temperature +se))
# Add these to our plot!! More manual way
ggplot(mapping = aes(x = treedensity, y = temperature, col = foresttype)) + # Note the mapping = aes
geom_point(data = suit) +
geom_line(data = glm.inttypden.predict) +
geom_ribbon(data = glm.inttypden.predict, mapping = aes(ymin = temperature - se, ymax = temperature + se, fill = foresttype),
col = NA, alpha = 0.4)
glm.specom.predict <- expand_grid(
species = c("A", "B"),
soilom = seq(from = 0, to = 40, by = 0.5)
)
glm.specom.predict <- glm.inttypden.predict %>%
mutate(orchidpa = glm.specom.predictobj$fit,
orchidpa.se = glm.specom.predictobj$se.fit)
glm.specom.predictobj <- predict(glm.specom, glm.specom.predict, type = "response", se.fit = T) # type = response back transforms for us
glm.specom.predict <- glm.inttypden.predict %>%
mutate(orchidpa = glm.specom.predictobj$fit,
orchidpa.se = glm.specom.predictobj$se.fit)
glm.specom.predict <- expand_grid(
species = c("A", "B"),
soilom = seq(from = 0, to = 40, by = 0.5)
)
glm.specom.predictobj <- predict(glm.specom, glm.specom.predict, type = "response", se.fit = T) # type = response back transforms for us
glm.specom.predict <- glm.inttypden.predict %>%
mutate(orchidpa = glm.specom.predictobj$fit,
orchidpa.se = glm.specom.predictobj$se.fit)
ggplot(mapping = aes(x = soilom, y = orchidpa, col = species)) +
geom_point(data = suit) +
geom_line(data = glm.specom.predict) +
facet_wrap( ~ species)
ggplot(mapping = aes(x = soilom, y = orchidpa, col = species)) +
geom_point(data = suit) +
geom_line(data = glm.specom.predict) +
geom_ribbon(data = glm.specom.predict,
mapping = aes(ymin = orchidpa=orchidpa.se,
ggplot(mapping = aes(x = soilom, y = orchidpa, col = species)) +
geom_point(data = suit) +
geom_line(data = glm.specom.predict) +
geom_ribbon(data = glm.specom.predict,
mapping = aes(ymin = orchidpa=orchidpa.se,
glm.specom.predict <- expand_grid(
species = c("A", "B"),
soilom = seq(from = 0, to = 40, by = 0.5)
)
glm.specom.predictobj <- predict(glm.specom, glm.specom.predict, type = "response", se.fit = T) # type = response back transforms for us
glm.specom.predict <- glm.inttypden.predict %>%
mutate(orchidpa = glm.specom.predictobj$fit,
orchidpa.se = glm.specom.predictobj$se.fit)
glm.specom.predict <- glm.specom.predict %>%
mutate(orchidpa = glm.specom.predictobj$fit,
orchidpa.se = glm.specom.predictobj$se.fit)
ggplot(mapping = aes(x = soilom, y = orchidpa, col = species)) +
geom_point(data = suit) +
geom_line(data = glm.specom.predict) +
geom_ribbon(data = glm.specom.predict,
mapping = aes(ymin = orchidpa=orchidpa.se,
ggplot(mapping = aes(x = soilom, y = orchidpa, col = species)) +
geom_point(data = suit) +
geom_line(data = glm.specom.predict) +
geom_ribbon(data = glm.specom.predict,
mapping = aes(ymin = orchidpa - orchidpa.se,
ymax = orchidpa+orchidpa.se,
fill = species),
col = NA, alpha = 0.4) +
facet_wrap( ~ species)
#you may need to install these first.
install.packages(c('pacman','devtools'))
#this code installs packages directly from github
devtools::install_github("daniel1noble/orchaRd", force = TRUE)
devtools::install_github("Mikata-Project/ggthemr", force = TRUE)
devtools::install_github("kassambara/ggpubr", force = TRUE)
pacman::p_load(tidyverse,
here,
DT,
ggpubr,
readxl,
metafor,
clubSandwich,
orchaRd,
MuMIn,
glmulti,
metagear,
patchwork,
stringr,
mice,
GoodmanKruskal,
networkD3,
ggplot2,
plotly,
ggsignif,
visdat,
ggalluvial,
ggthemr,
cowplot,
grDevices,
png,
grid,
gridGraphics,
pander,
formatR,
ggbeeswarm
)
source("custom_func.R")
### import dataset
dat_Midolo_2019 <- read.csv("Midolo_2019_Global Change Biology.csv")
### drop unused columns
dat_Midolo_2019 <- dat_Midolo_2019[,which(colnames(dat_Midolo_2019) %in% c("Study_ID", "study_name", "species", "trait", "treatment", "control", "sd_treatment", "sd_control", "n_treatment", "n_control", "elevation", "elevation_log"))]
### make a table
t1 <- dat_Midolo_2019 %>% DT::datatable()
t1
lnRR <- escalc(measure = "ROM",  # "ROM" means ratio of means; lnRR is specified to be calculated (alternative effect sizes: "SMD" – SMD, "CVR" – lnCVR, "VR" – lnVR; see below);
m1i = treatment, # mean value of of group 1 (e.g., environmental stressor); in our worked example, m1i denotes the mean value of a trait measured at the higher elevation level;
m2i = control, # mean value of group 2 (e.g., control); in our worked example, m2i denotes the mean of the same trait measured at the lower elevation level;
sd1i = sd_treatment, # standard deviation of mean of group 1 (e.g., environmental stressor)
sd2i = sd_control, # standard deviation of group 2 (e.g., control)
n1i = n_treatment, # sample size of group 1 (e.g., environmental stressor)
n2i = n_control, # sample size of group 2 (e.g., control)
data = dat_Midolo_2019, # dataset containing the above information (here is the dataset of our working example)
)
# computation lnRR
lnRR <- escalc(measure = "ROM",  # the lnRR is specified; "ROM" means ratio of means
m1i = treatment, # mean of group 1 (e.g., group to which environmental stressor applied)
m2i = control, # mean of group 2 (e.g., control group)
sd1i = sd_treatment, # standard deviation of mean of group 1
sd2i = sd_control, # standard deviation of group 2
n1i = n_treatment, # sample size of group 1
n2i = n_control, # sample size of group 2
data = dat_Midolo_2019, # dataset containing the above information (here is the dataset of our working example)
digits = 3,
append = FALSE)
### bind the effect size estimates and study variables into a single dataframe
metrics_set <- data.frame(lnRR = lnRR$yi, lnRRV = lnRR$vi) # effect size estimate and its variance
dat2_Midolo_2019 <- cbind(dat_Midolo_2019, metrics_set) # bind_cols()
### show the calculated effect sizes and their sampling variances
t2 <- dat2_Midolo_2019 %>% select(c("study_name","lnRR","lnRRV", "elevation")) %>% DT::datatable()
t2
mod_FE_lnRR <- rma(yi = lnRR, # calculated/estimated effect size are supplied; the outputs of escalc() function;
vi = lnRRV, # calculated/estimated sampling variance of lnRR are supplied;
method = "EE", # fixed-effect model is specified;
data = dat2_Midolo_2019) # our dataset
# the model results of the fixed-effect model
summary(mod_FE_lnRR)
### fit a fixed-effect model, it also can be called common-effect model or equal-effect model
mod_RE_lnRR <- rma(yi = lnRR, # observed effect sizes / estimates of SMD; the outputs of escalc() function;
vi = lnRRV, # the estimates of sampling variance of SMD;
method = "REML", # setting restricted maximum likelihood estimator as the estimators for the amount of heterogeneity;
data = dat2_Midolo_2019 # the dataset
)
# the model results of the random-effects model
summary(mod_RE_lnRR)
# add a unique ID for each observation; otherwise you would be assuming homogeneity of true effect sizes within studies, which is a strong assumption
dat2_Midolo_2019$ES_ID <- rep("ES", nrow(dat2_Midolo_2019))
dat2_Midolo_2019$ES_ID <- paste(dat2_Midolo_2019$ES_ID, c(1:nrow(dat2_Midolo_2019)), sep = "")
mod_ML_lnRR <- rma.mv(yi = lnRR,
V = lnRRV,
random = list(~1 | Study_ID, # allows true effect sizes to vary among different primary studies - account for the between-study effect and quantify between-study heterogeneity;
~1 | ES_ID), # allows true effect sizes to vary within primary studies - account for the with-study effect and quantify with-study heterogeneity;
method = "REML", # REML is assigned as the estimator for variance components as suggested;
#test = "t",
data = dat2_Midolo_2019 # our dataset
)
summary(mod_ML_lnRR)
#Comparison of the random-effects and multilevel meta-analytic models.
t3 <- data.frame("Overall effect (pooled lnRR)" = c(round(mod_RE_lnRR$b[1],2), round(mod_ML_lnRR$b[1],2)),
"Standard error" = c(round(mod_RE_lnRR$se,2), round(mod_ML_lnRR$se,2)),
"p-value" = c(round(mod_RE_lnRR$pval,4), round(mod_ML_lnRR$pval,3)),
"Lower CI" = c(round(mod_RE_lnRR$ci.lb,2), round(mod_ML_lnRR$ci.lb,2)),
"Upper CI" = c(round(mod_RE_lnRR$ci.ub,2), round(mod_ML_lnRR$ci.ub,2)),
"Between-study variance" = c(round(mod_RE_lnRR$tau2,3), round(mod_ML_lnRR$sigma2[1],3)),
"Within-study variance" = c(0, round(mod_ML_lnRR$sigma2[2],3)),
"Between-study I2" = c(round(mod_RE_lnRR$I2,2),round(i2_ml(mod_ML_lnRR)[[2]],2)),
"Within-study I2" = c(0,round(i2_ml(mod_ML_lnRR)[[3]],2)))
colnames(t3) <- c("Overall effect (pooled lnRR)", "Standard error", "p-value", "Lower CI", "Upper CI", "Between-study variance", "Within-study variance", "Between-study heterogeneity I2 (%)", "Within-study heterogeneity I2 (%)")
t3_2 <- t(t3) %>% as.data.frame()
colnames(t3_2) <- c("random-effects model", "Multi-level model")
t3_2 %>% DT::datatable()
#SE
round(mod_ML_lnRR$se,3) #in the multilevel model
#vs.
round(mod_RE_lnRR$se,3) #in the random-effects model;
#p-value
round(mod_ML_lnRR$pval,4) #in the multilevel model
#vs.
round(mod_RE_lnRR$pval,4) #in the random-effects model.
#The width of 95% CIs in the multilevel model are wider than those in the random-effects model:
round(mod_ML_lnRR$ci.lb,3)
round(mod_ML_lnRR$ci.ub,3) #in the multilevel model
#vs.
round(mod_RE_lnRR$ci.lb,3)
round(mod_RE_lnRR$ci.ub,3) #in the random-effects model.
#The multilevel model accounts for statistical non-independence due to multiple effect sizes derived from the same study.
#We can quantify the degree of dependence using an index called the intraclass correlation coefficient:
#The *ICC* index can reflect the intraclass correlation of the true effects within the same study.
#In the above fitted model, the *ICC* can be computed with:
mod_ML_lnRR$sigma2[1] / sum(mod_ML_lnRR$sigma2)
VCV <- impute_covariance_matrix(vi = dat2_Midolo_2019$lnRRV, # sampling variances that are correlated with each within the same study;
cluster = dat2_Midolo_2019$Study_ID, # study identity - clustering variable;
r = 0.5 # assuming that the effect sizes within the same study are correlated with rho = 0.5.
)
#Setting `rho = 0.5` means we assume that sampling errors within the same study are correlated with rho = 0.5
#(see below for **Technical Recommendation**).
#Let's see what the imputed **VCV** matrix looks like. Let's use the Bansal and Germino (2010) study as an example:
VCV[dat2_Midolo_2019$study_name %in% c("Bansal and Germino (2010)"), dat2_Midolo_2019$study_name %in% c("Bansal and Germino (2010)")] %>% round(3)
mod_MLMR_lnRR_elevation <- rma.mv(yi = lnRR,
V = VCV,
mods = ~ elevation_log, # adding elevation as a moderator variable (for continuous variable, it is a good practice to log-transform them to avoid data skewness);
random = list(~1 | Study_ID,
~1 | ES_ID),
method = "REML",
test = "t",
data = dat2_Midolo_2019,
sparse = TRUE
)
### run multilevel model without accounting for sampling covariance (correlated errors)
mod_ML_lnRR_var <- rma.mv(yi = lnRR,
V = lnRRV, # use sampling variance for comparison with that fitted by covariance
random = list(~1 | Study_ID,
~1 | ES_ID),
method = "REML",
test = "t",
data = dat2_Midolo_2019,
sparse = TRUE
)
# re-run the multilevel model with accounting for the sampling variance using the constructed VCV matrix with rho = 0.5 - medium correlation
mod_ML_lnRR_VCV <- rma.mv(yi = lnRR,
V = VCV, # use covariance for comparison with that fitted by sampling covariance
random = list(~1 | Study_ID,
~1 | ES_ID),
method = "REML",
test = "t",
data = dat2_Midolo_2019,
sparse = TRUE
)
# show the summary of the model account for correlated errors
summary(mod_ML_lnRR_VCV)
#We see that the overall effect beta_0 does not change
round(mod_ML_lnRR_VCV$beta,3)
round(mod_ML_lnRR_var$beta,3)
#95% CIs do not really change
round(mod_ML_lnRR_VCV$ci.lb,3)
round(mod_ML_lnRR_VCV$ci.ub,3)
round(mod_ML_lnRR_var$ci.lb,3)
round(mod_ML_lnRR_var$ci.ub,3)
#and corresponding significance tests such as the *p-value* =
round(mod_ML_lnRR_VCV$pval,4)
round(mod_ML_lnRR_var$pval,4)
i2_ml(mod_ML_lnRR_VCV)
mod_MLMR_lnRR_elevation <- rma.mv(yi = lnRR,
V = VCV,
mods = ~ elevation_log, # adding elevation as a moderator variable (for continuous variable, it is a good practice to log-transform them to avoid data skewness);
random = list(~1 | Study_ID,
~1 | ES_ID),
method = "REML",
test = "t",
data = dat2_Midolo_2019,
sparse = TRUE
)
# print model results
summary(mod_MLMR_lnRR_elevation)
#The results of the above fitted meta-regression model are very similar with those of a multilevel meta-analytic model
summary(mod_ML_lnRR_VCV)
mod_MLMR_lnRR_trait <- rma.mv(yi = lnRR,
V = VCV,
mods = ~ trait -1, # setting '-1' is a useful strategy to remove intercept and then directly obtain the estimated effect (slope) for each subgroup or for a particular level within the categorical moderator.
random = list(~1 | Study_ID,
~1 | ES_ID),
method = "REML",
test = "t",
data = dat2_Midolo_2019
)
#The corresponding model output is then:
summary(mod_MLMR_lnRR_trait)
#- **Technical Recommendation**
#Setting `mods = ~ x` (in this case, `mods = ~ trait`) will keep intercept (beta_0) in the model:
mod_MLMR_lnRR_trait2 <- rma.mv(yi = lnRR,
V = VCV,
mods = ~ I(trait),
random = list(~1 | Study_ID,
~1 | ES_ID),
method = "REML",
test = "t",
data = dat2_Midolo_2019
)
# summary results
summary(mod_MLMR_lnRR_trait2)
r2_ml(mod_MLMR_lnRR_elevation)
forest(mod_ML_lnRR_VCV, # rma.mv object
xlab = "Effect size lnRR")
orchard_plot(mod_ML_lnRR_VCV,
mod = "1",
xlab = "Effect size lnRR",
group = "Study_ID",  k = TRUE, g = TRUE, trunk.size = 1.5,
data = dat2_Midolo_2019) +
scale_x_discrete(labels = c("Overall effect"))
### calculate the 95% prediction intervals
predict(mod_ML_lnRR_VCV)
#Orchard plot (forest-like plot) showing the effect sizes from each study and the overall effect for each subgroup/levels of a given categorical moderator.
orchard_plot(mod_MLMR_lnRR_trait,
mod = "trait",
xlab = "Effect size lnRR",
group = "Study_ID",  k = TRUE, g = TRUE, trunk.size = 1.5,
data = dat2_Midolo_2019) +
scale_x_discrete(labels = c("SLA","Pmass","Nmass","Narea","LMA","LA","dC13"))
#Bubble plot showing the results of a meta-regression model:
#relationship between a continuous moderator (in our case, *elevation*) and effect size magnitude (lnRR).
bubble_plot(mod_MLMR_lnRR_elevation,
mod = "elevation_log",
xlab = "Elevation (log-transformed)", ylab = "Effect size lnRR",
group = "Study_ID",k = TRUE, g = TRUE,
data = dat2_Midolo_2019, legend.pos = "top.left") +
theme(axis.text.x = element_text(size = 12, colour = "black"),
axis.text.y = element_text(size = 12, colour = "black"),
axis.title.x = element_text(size = 12, colour = "black"),
plot.title = element_text(size = 12, colour = "black"))
ess.var_cal <- function(dat){1/dat$n_control + 1/dat$n_treatment} # write a help function to calculate adapted sampling variance based on effective size based  - tilde n
dat2_Midolo_2019$ess.var <- ess.var_cal(dat2_Midolo_2019) # calculate tilde N
dat2_Midolo_2019$ess.se <- sqrt(dat2_Midolo_2019$ess.var) # calculate adapted sampling error based on effective size - tilde square root n
#Then the Equation 16 can be fitted with:
mod_MLMR_lnRR_ess.se <- rma.mv(yi = lnRR,
V = VCV,
mods = ~ ess.se, # add adjusted based sampling error - tilde square root n as a moderator to test small study effect.
random = list(~1 | Study_ID,
~1 | ES_ID),
method = "REML",
test = "t",
data = dat2_Midolo_2019
)
#The outputs of the above fitted model are exactly the same as those of a meta-regression model:
# summary results
summary(mod_MLMR_lnRR_ess.se)
#Bubble plot showing the relationship between the effect size magnitude and its adjusted sampling error
#(effective sample size based). Small studies (low precision or high SE) do not report large effect sizes.
bubble_plot(mod_MLMR_lnRR_ess.se,
mod = "ess.se",
xlab = "Adjusted sampling error", ylab = "Effect size lnRR",
group = "Study_ID", k = TRUE, g = TRUE,
data = dat2_Midolo_2019, legend.pos = "top.left") +
theme(axis.text.x = element_text(size = 12, colour = "black"),
axis.text.y = element_text(size = 12, colour = "black"),
axis.title.x = element_text(size = 12, colour = "black"),
plot.title = element_text(size = 12, colour = "black"))
# make a funnel plot
#Visual inspection of the typical funnel plot to identify the small study effect.
funnel(mod_MLMR_lnRR_ess.se, yaxis = "seinv",
xlim = c(-3, 3),
ylab = "Precision (1/SE)",
xlab = "Effect size lnRR")
# calculate tilde N
n_tilde_cal <- function(dat){(dat$n_control * dat$n_treatment) / (dat$n_control + dat$n_treatment)}
dat2_Midolo_2019$n_tilde <- n_tilde_cal(dat2_Midolo_2019)
#Visual inspection of the funnel plot based on effective sample size to identify the small study effect.
funnel(dat2_Midolo_2019$lnRR, dat2_Midolo_2019$lnRRV, ni = dat2_Midolo_2019$n_tilde,
yaxis = "ni",
xlim = c(-3, 3),
ylab = "Effective sample size",
xlab = "Effect size (lnRR)")
### create a variable containing publication year
dat2_Midolo_2019 <- dat2_Midolo_2019 %>% mutate(Year = as.integer(str_extract(study_name,"\\d+")))
### center publication year to ease interpretation of the results
dat2_Midolo_2019$Year.c <- dat2_Midolo_2019$Year - mean(dat2_Midolo_2019$Year) # we will use this variable as a predictor to estimate decline effect
#Equation 18 can be fitted with code:
mod_MLMR_lnRR_Year.c <- rma.mv(yi = lnRR,
V = VCV,
mods = ~ Year.c, # add centered year as a moderator to detect decline effect.
random = list(~1 | Study_ID,
~1 | ES_ID),
method = "REML",
test = "t",
data = dat2_Midolo_2019,
sparse = TRUE
)
# summary results
summary(mod_MLMR_lnRR_Year.c)
#Bubble plot showing the relationship between the effect size magnitude and publication year (centered on 2008). There is no temporal trend in the changes of the effect size magnitude.
bubble_plot(mod_MLMR_lnRR_Year.c,
mod = "Year.c",
xlab = "Publication year (centered on 2008)", ylab = "Effect size lnRR",
group = "Study_ID", k = TRUE, g = TRUE,
data = dat2_Midolo_2019, legend.pos = "top.left") +
theme(axis.text.x = element_text(size = 12, colour = "black"),
axis.text.y = element_text(size = 12, colour = "black"),
axis.title.x = element_text(size = 12, colour = "black"),
plot.title = element_text(size = 12, colour = "black"))
mod_MLMR_lnRR_ess.var <- rma.mv(yi = lnRR,
V = VCV,
mods = ~ ess.var, # adding adjusted sampling error to obtain publication-bias-corrected overall effect - which is potentially regarded as 'true' effect.
random = list(~1 | Study_ID,
~1 | ES_ID),
method = "REML",
test = "t",
data = dat2_Midolo_2019,
sparse = TRUE
)
# summary results
summary(mod_MLMR_lnRR_ess.var)
### make a table to compare the original effect size and the adjusted effect size
t4 <- data.frame("Overall effect" = c(round(mod_ML_lnRR_VCV$b[1],4), round(mod_MLMR_lnRR_ess.var$b[1],4)),
"Standard error" = c(round(mod_ML_lnRR_VCV$se,4), round(mod_MLMR_lnRR_ess.var$se[1],4)),
"p-value" = c(round(mod_ML_lnRR_VCV$pval,3), round(mod_MLMR_lnRR_ess.var$pval[1],3)),
"Lower CI" = c(round(mod_ML_lnRR_VCV$ci.lb,4), round(mod_MLMR_lnRR_ess.var$ci.lb[1],4)),
"Upper CI" = c(round(mod_ML_lnRR_VCV$ci.ub,4), round(mod_MLMR_lnRR_ess.var$ci.ub[1],4)))
colnames(t4) <- c("Overall effect", "Standard error", "p-value", "Lower CI", "Upper CI")
t4_2 <- t(t4) %>% as.data.frame()
colnames(t4_2) <- c("Original estimate", "Bias-corrected estimate")
t4_2 %>% DT::datatable()
#there's a lot more in the main tutorial so do take a look at it in its entirety. This R script is just an easier way
